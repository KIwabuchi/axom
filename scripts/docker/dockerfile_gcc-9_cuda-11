# This script can be run with the following command from the root axom directory:
# docker build --build-arg branch=<your branch here, defaults to develop> -t "axom/tpls:gcc-9-cuda-11" -f ./scripts/docker/dockerfile_gcc-9_cuda-11 .

# Command to launch openvscode server with the resulting docker image:
# docker run -it --init -p 3000:3000 -v "$(pwd):/home/workspace:cached" <image id>

FROM ghcr.io/rse-ops/cuda-ubuntu-20.04:cuda-11.1.1
ARG branch=feature/han12/docker_tutorial
ARG USER=axomdev
ENV HOME /home/${USER}

SHELL ["/bin/bash", "-c"]
RUN sudo apt-get update -y
RUN sudo apt-get install -y supervisor
RUN sudo useradd --create-home --shell /bin/bash ${USER}
RUN sudo apt-get install doxygen gfortran graphviz libopenblas-dev libomp-dev mpich python3-sphinx ssh texlive-full -fy

WORKDIR /opt/archives
RUN curl -L https://github.com/gitpod-io/openvscode-server/releases/download/openvscode-server-v1.69.1/openvscode-server-v1.69.1-linux-x64.tar.gz > \
    /opt/archives/openvscode-server-v1.69.1-linux-x64.tar.gz
RUN tar xzf openvscode-server-v1.69.1-linux-x64.tar.gz && chown -R ${USER}:${USER} openvscode-server-v1.69.1-linux-x64

WORKDIR ${HOME}
COPY . $HOME/axom
RUN chown -R axomdev:axomdev $HOME 

#WORKDIR "/home/axom"
USER ${USER}

#COPY --chown=axomdev:axomdev . $HOME/axom
RUN cd ${HOME}/axom && git submodule update --init 
#RUN cd ${HOME} && git clone --recursive --branch $branch --single-branch --depth 1 https://github.com/LLNL/axom.git axom_repo

# Build/install TPLs via spack and then remove the temporary build directory on success

RUN cd ${HOME}/axom && python3 ./scripts/uberenv/uberenv.py --spack-env-file=./scripts/spack/configs/docker/ubuntu20_cuda/spack.yaml \
                                                         --project-json=.uberenv_config.json \
                                                         --spec="%gcc@9.3.0+mfem+cuda cuda_arch=70" \
                                                         --prefix=${HOME}/axom/axom_tpls -k \
                 && rm -rf ${HOME}/axom_tpls/builds

#RUN cd ${HOME}/axom_repo && python3 ./scripts/uberenv/uberenv.py --spack-env-file=./scripts/spack/configs/docker/ubuntu20_cuda/spack.yaml \
#                                                         --project-json=.uberenv_config.json \
#                                                         --spec="%gcc@9.3.0+mfem+cuda cuda_arch=70" \
#                                                         --prefix=${HOME}/axom_tpls -k \
#                 && rm -rf ${HOME}/axom_tpls/builds

#RUN mkdir -p ${HOME}/export_hostconfig
#RUN cp ${HOME}/axom_repo/*.cmake ${HOME}/export_hostconfig

# Make sure the new hostconfig worked
# Note: having high job slots causes build log to disappear and job to fail
#RUN cd ${HOME}/axom_repo && python3 config-build.py -hc *.cmake -bp build && cd build && make -j4 && make -j4 test

# Omit testing step, hangs at slam_lulesh unit test (same behavior for azure pipeline images, as well)
RUN cd ${HOME}/axom && python3 config-build.py -hc *cuda.cmake -bp ${HOME}/build && cd ${HOME}/build && make -j4


USER root
ADD ./scripts/docker/supervisord.conf /etc/supervisord.conf
RUN sed -i "s/XXX/${USER}/g" /etc/supervisord.conf

RUN touch /var/log/openvscode-server.log && chown -R ${USER}:${USER} /var/log/openvscode-server.log

CMD ["/usr/bin/supervisord"]
